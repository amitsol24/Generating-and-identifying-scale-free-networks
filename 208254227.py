# -*- coding: utf-8 -*-
"""208254227.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aJjnAAV-glonMtH3cYviiNEOXDX-6Bez
"""

# !pip install networkx
# !pip install powerlaw
import networkx as nx
import numpy as np
import pandas as pd
import scipy.stats as stats
from scipy.stats import binom_test
import matplotlib.pyplot as plt
import powerlaw

def get_name():
  return 'Amit Sol'

def get_id():
  return 208254227

"""#Question 1

#i
"""

def random_networks_generator(n,p,num_networks=1,directed=False,seed=208254227):
  lst = []
  for i in range(num_networks):
      G=nx.erdos_renyi_graph(n, p, seed + i, directed)
      lst.append(G)
  return lst

"""#ii"""

def network_stats(network_object):
  degree_sequence = sorted((d for n, d in network_object.degree()), reverse=True)
  degrees_avg = np.average(np.asarray(degree_sequence))
  degrees_std = np.std(np.asarray(degree_sequence))
  degrees_min = min(degree_sequence)
  degrees_max = max(degree_sequence)
  spl = nx.average_shortest_path_length(network_object)
  diameter = nx.diameter(network_object)
  statistics_dict = {'degrees_avg':degrees_avg,'degrees_std':degrees_std,'degrees_min':degrees_min,'degrees_max':degrees_max,'spl':spl,'diameter':diameter}
  return statistics_dict

"""#iii"""

def networks_avg_stats(lst):
  dict_list = []
  
  for graph in lst:
    statistics_dict = network_stats(graph)
    dict_list.append(statistics_dict)
  
  key_sum = {}

  for dictionary in dict_list:
      for key, value in dictionary.items():
          if key in key_sum:
              key_sum[key] += value
          else:
              key_sum[key] = value
  key_avg = {key: value / len(dict_list) for key, value in key_sum.items()}

  return key_avg

"""#iv"""

# type_a = random_networks_generator(100,0.1,num_networks=20,directed=False,seed=208254227)
# print("type_a")
# for i in type_a:
#   print(network_stats(i))
# dict_type_a = networks_avg_stats(type_a)
# type_b= random_networks_generator(100,0.6,num_networks=20,directed=False,seed=208254227)
# print("type_b")
# for i in type_b:
#   print(network_stats(i))
# dict_type_b = networks_avg_stats(type_b)
# type_c = random_networks_generator(1000,0.1,num_networks=10,directed=False,seed=208254227)
# print("type_c")
# for i in type_c:
#   print(network_stats(i))
# dict_type_c = networks_avg_stats(type_c)
# type_d=  random_networks_generator(1000,0.6,num_networks=10,directed=False,seed=208254227)
# print("type_d")
# for i in type_d:
#   print(network_stats(i))
# dict_type_d = networks_avg_stats(type_d)
# print("stat")
# print(dict_type_a)
# print(dict_type_b)
# print(dict_type_c)
# print(dict_type_d)

"""#Question 2

#i
"""

# df = pd.read_pickle('rand_nets.p')
# print(df)

"""#ii"""

def rand_net_hypothesis_testing(network,theoretical_p,alpha=0.05):
  edges = network.number_of_edges()
  n = network.number_of_nodes()
  clique = int((n*(n-1))/2)
  p_value = binom_test(edges,clique,theoretical_p,alternative='two-sided')
  if alpha > p_value:
    return (p_value,'reject')
  else:
    return (p_value,'accept')

"""#iii"""

def most_probable_p(graph):
  possible_p = [0.01,0.1,0.3,0.6]
  lst = []
  for i in possible_p:
    solution = rand_net_hypothesis_testing(graph,i)
    if solution[1] == 'accept':
      lst.append((i,solution[0]))
  if len(lst) == 0:
    return -1
  else:
    sorted_list = sorted(lst, key=lambda x: x[1], reverse=True)
    return sorted_list[0][0]

"""#iv"""

# for i in df:
#   print(most_probable_p(i))

# p = rand_net_hypothesis_testing(df[0],0.66)
# print("hypothesis testing to the same network with a p bigger by 10% ",p)
# p1 = rand_net_hypothesis_testing(df[0],0.54)
# print("hypothesis testing to the same network with a p smaller by 10% ",p1)


# #bigger network
# n = df[0].number_of_nodes()



# G=nx.erdos_renyi_graph(5000, 0.6)
# p_1 = rand_net_hypothesis_testing(G,0.66)
# print("hypothesis testing to a bigger network with a p bigger by 10% ",p_1)
# p_2 = rand_net_hypothesis_testing(G,0.54)
# print("hypothesis testing to a bigger network with a p smaller by 10% ",p_2)

"""#v"""

# # Calculate the degree distribution
# degrees = [df[0].degree(n) for n in df[0].nodes()]
# mean_degree = np.mean(degrees)
# std_degree = np.std(degrees)

# z = (degrees-np.mean(degrees))/np.std(degrees)
# stats.probplot(z, dist="norm", plot=plt)
# plt.title("Normal Q-Q plot")
# plt.show()

"""#3

#i
"""

# df2 = pd.read_pickle('scalefree_nets.p')
# print(df2)

"""#ii"""

def find_opt_gamma(network,treat_as_social_network=True):
  degrees = [network.degree(node) for node in network.nodes()]
  fit = powerlaw.Fit(degrees,discrete=treat_as_social_network)
  gamma = fit.power_law.alpha
  return gamma

"""#iii"""

# for i in df2:
#   print(find_opt_gamma(i))

"""#iv"""

# for i in df2:
#   print(i.number_of_edges(),i.number_of_nodes())
# print(' ')
# for i in df:
#   print(i.number_of_edges(),i.number_of_nodes())

# print("scale free network ",network_stats(df2[6]))
# print("random network ",network_stats(df[6]))

"""#4

#i
"""

# data = pd.read_pickle('mixed_nets.p')
# print(data)

"""#ii"""

def netwrok_classifier(network):
  gamma = find_opt_gamma(network)
  if 2<gamma<3:
    return 2
  if gamma>=3:
    return 1

"""#iii"""

# for i in data:
#   print(netwrok_classifier(i))